{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h2>Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación</h2>\n",
    "<h3>Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones 2020</h3>\n",
    "<h4>Busqueda y Recomendación de Textos Legales - Preprocesamiento</h4>\n",
    "</center>\n",
    "</left>\n",
    "<h4>Mentor: Claudio Sarate</h4>\n",
    "</left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción\n",
    "\n",
    "En esta notebook, se implementara los pasos necesarios para el preprocesamiento de una de los archivos de muestra tomados de la base de Información Legislativa (INFOLEG) con la idea de generar un Corpus de texto para el posterior proceso. Para ello, comenzaremos con las importaciones pertinentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint as pprint\n",
    "\n",
    "from IPython.display import display\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import defaultdict\n",
    "\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "# %load_ext lab_black\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield gensim.models.doc2vec.LabeledSentence(doc, [self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Se verfica entorno de ejecución\n",
    "in_colab = \"google.colab\" in sys.modules\n",
    "\n",
    "if in_colab:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    BASE_DIR = \"/content/drive/My Drive/Colab Notebooks/Data/\"\n",
    "else:\n",
    "    BASE_DIR = \"./Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Inicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de directorios y nombres para el corpus a procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "train_data_dir = \"{}\".format(os.sep).join([BASE_DIR, \"Infoleg/\"])\n",
    "train_data = train_data_dir + \"Infoleg.cor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Data/Infoleg/'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'./Data/Infoleg/Infoleg.cor'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_data_dir)\n",
    "display(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedimiento para barrido del directorio donde estan los archivos con los cuales generar el Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    train = next(os.walk(train_data_dir))\n",
    "except StopIteration:\n",
    "    pass  # Some error handling here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Generacion del Corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Concatenación de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Limpieza del texto con la opción remover stopwords\n",
    "\n",
    "\n",
    "def review_to_wordlist(review, remove_stopwords=False):\n",
    "\n",
    "    # Conversión de palabras a minúsculas y separación\n",
    "    words = review.lower().split()\n",
    "    \n",
    "    review_text = \" \".join(words)\n",
    "\n",
    "    # Opcionalmente se remueven stop words (true por default)\n",
    "\n",
    "    # Return a list of words\n",
    "    return review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "docLabels = []\n",
    "row_list = []\n",
    "i = 0\n",
    "\n",
    "for folder, subfolders, filenames in os.walk(train_data_dir):\n",
    "    for file in filenames:\n",
    "        if file.endswith(\".txt\"):\n",
    "            d = {folder}\n",
    "            with open(folder + file) as f:\n",
    "                if f.read():\n",
    "                    f.seek(0)\n",
    "                    d = f.read()\n",
    "                    docLabels.append(folder + file)\n",
    "                    row_list.append(review_to_wordlist(d))\n",
    "                    i = i + 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos txt de entrenamiento leidos 2500 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(u\"Archivos txt de entrenamiento leidos %s \\n\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ministerio de trabajo, empleo y seguridad soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>administracion federal de ingresos publicos di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>administración federal de ingresos públicos ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(nota infoleg: norma abrogada por art. 2° de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>secretaria de ciencia, tecnologia e innovacion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ministerio de defensa decreto 524/2007 desígna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>banco central de la republica argentina ( b.c....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ministerio de trabajo, empleo y seguridad soci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>banco central de la republica argentina (b.c.r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>consejo federal de la juventud ley 26.227 créa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  ministerio de trabajo, empleo y seguridad soci...\n",
       "1  administracion federal de ingresos publicos di...\n",
       "2  administración federal de ingresos públicos ob...\n",
       "3  (nota infoleg: norma abrogada por art. 2° de l...\n",
       "4  secretaria de ciencia, tecnologia e innovacion...\n",
       "5  ministerio de defensa decreto 524/2007 desígna...\n",
       "6  banco central de la republica argentina ( b.c....\n",
       "7  ministerio de trabajo, empleo y seguridad soci...\n",
       "8  banco central de la republica argentina (b.c.r...\n",
       "9  consejo federal de la juventud ley 26.227 créa..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(row_list)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df_train.to_csv(train_data, sep=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
