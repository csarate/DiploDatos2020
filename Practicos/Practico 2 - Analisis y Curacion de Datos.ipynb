{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universidad Nacional de Córdoba - Facultad de Matemática, Astronomía, Física y Computación\n",
    "\n",
    "#### Diplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones 2020\n",
    "\n",
    "Búsqueda y Recomendación de Textos Legales - Análisis y Curación de Datos\n",
    "\n",
    "Mentor: Claudio Sarate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este práctico radica en el manejo de los datos desde distintas fuentes posibles dejandolas en un formato común que conformara el corpus de trabajo, para luego realizar los procesos correspondientes de normalización, para así volver a realizar el análisis que ya realizaron en el punto de AyV, evaluando si aquellas consideraciones que se encontraron al trabajar con datos crudos cambian en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enunciado del práctico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armar el corpus con diferentes fuentes de datos (txt, doc, pdf, etc.).\n",
    "\n",
    "Investigar si existen otras fuentes de las cuales agregar datos al corpus y sumarlas. Mantengan un tamaño de corpus razonable para que en esta etapa el proceso pueda realizarse en tiempos no muy largos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se deberán aplicar diferentes normalizaciones, según el dominio: separar puntuación, pasar a lowercase, tokenización, stemming, lematización, eliminar stopwords (o no), eliminar las palabras con frecuencia menor a n, sustituir palabras con demasiada variabilidad (p.ej. números) con un placeholder (p.ej. DÍGITO)… después de cada una de estas procesos, volver a visualizar el histograma de frecuencia de palabras y analizar resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer una explicación con ejemplos tomando algunas palabras al azar entre lo que es stemming y lemmatizing para entender que nos da cada uno de estos procesos y cual es conveniente utilizar en cada caso. Investigar sobre la madurez en nuestro idioma del uso de estos procesos ya que la mayoría de las soluciones estan pensadas para idioma inglés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explorar el impacto de diferentes normalizaciones en la frecuencia de palabras, en la IM para detectar secuencias de palabras valiosas y en la IM con categorías gramaticales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo podríamos hacer para integrar las secuencias de palabras con alta IMP en nuestro preproceso de los datos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Representar las palabras como vectores, donde las dimensiones son… otras palabras? contextos? categorías? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-uk_AAf5MSL"
   },
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formato de entrega: Deberán utilizar esta notebook con los códigos con los que hicieron el análisis y los anaálisis y conclusiones despues de cada proceso. \n",
    "\n",
    "Fecha de entrega: 19/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ----------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
